<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lukas Fischer</title>
    <link>https://cornua1.github.io/</link>
    <description>Recent content on Lukas Fischer</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>©2020-2024 Lukas Fischer</copyright>
    <lastBuildDate>Sun, 25 Oct 2020 23:18:45 -0400</lastBuildDate>
    <atom:link href="https://cornua1.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Virtual poster presentations with blender</title>
      <link>https://cornua1.github.io/posts/semidynamic_presentation/</link>
      <pubDate>Sun, 25 Oct 2020 23:18:45 -0400</pubDate>
      <guid>https://cornua1.github.io/posts/semidynamic_presentation/</guid>
      <description>&lt;p&gt;&lt;del&gt;Recently&lt;/del&gt; Six months ago I submitted a poster to a small conference that has been moved onto a virtual platform because of the ongoing pandemic. Every participant had to create a 60-second long video presentation of their submission, with the only other instruction being &amp;lsquo;be creative&amp;rsquo;.&lt;/p&gt;&#xA;&lt;p&gt;Making such a presentation in a somewhat polished way turned out to be a little more challenging than expected. I decided to use &lt;a href=&#34;https://www.blender.org/&#34;&gt;blender&lt;/a&gt; because it provides a powerful suite to be creative in almost any conceivable way. In my case, I wanted to move smoothly between parts of the poster, cue up the audio and play videos places where otherwise there would only be static figure panels. However, blender can also be a little difficult. For example, the way it handles lighting, or rendering textures in the distance is not made for this purpose and can make a presentation look blurry and washed out. Thats why I decided to write a post about the settings I found useful tricks to get sharp text and crisp colors similar to what you would expect when you make your poster in a graphics editor. I won&amp;rsquo;t be providing step-by-step instructions for things where people have made better instructional videos already. I will be linking those videos instead. Some blender experience is necessary, but there are many truly excellent videos out there that explain how blender works.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Publications</title>
      <link>https://cornua1.github.io/publications/publications/</link>
      <pubDate>Sun, 12 Apr 2020 11:02:14 -0400</pubDate>
      <guid>https://cornua1.github.io/publications/publications/</guid>
      <description>&lt;h3 id=&#34;journal-publications&#34;&gt;Journal Publications&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Fischer, L.&lt;/strong&gt;, Xu L., Murray K., Harnett M. T. Learning to use landmarks for navigation amplifies their representation in retrosplenial cortex. bioRxiv 2024.08.18.607457&lt;br&gt;&#xA;&lt;a href=&#34;https://doi.org/10.1101/2024.08.18.607457&#34;&gt;article&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Weihua D.*, &lt;strong&gt;Fischer L.*&lt;/strong&gt;, …, Harnett M. T., Shiqian S., Highly synchronized cortical circuit dynamics mediate spontaneous pain in mice. J Clin Invest. 2023;133(5):e166408.&lt;br&gt;&#xA;&lt;a href=&#34;https://doi.org/10.1172/jci166408&#34;&gt;article&lt;/a&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://www.jci.org/133/5&#34;&gt;cover story&lt;/a&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://doi.org/10.1172/JCI167814&#34;&gt;comment&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Fischer, L.&lt;/strong&gt;, Mojica Soto-Albors, R., Buck, F., &amp;amp; Harnett, M. T. (2020). Representation of visual landmarks in retrosplenial cortex. ELife, 9, 811430.&lt;br&gt;&#xA;&lt;a href=&#34;https://doi.org/10.7554/eLife.51458&#34;&gt;article&lt;/a&gt;&lt;br&gt;&#xA;&lt;a href=&#34;http://news.mit.edu/2020/brain-encodes-landmarks-navigate-0310&#34;&gt;MIT News&lt;/a&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://elifesciences.org/digests/51458/virtual-reality-for-mice&#34;&gt;eLife digest showcase&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Contact</title>
      <link>https://cornua1.github.io/contact/</link>
      <pubDate>Sun, 12 Apr 2020 10:57:16 -0400</pubDate>
      <guid>https://cornua1.github.io/contact/</guid>
      <description>&lt;h3 id=&#34;contact&#34;&gt;Contact:&lt;/h3&gt;&#xA;&lt;p&gt;E-mail: &lt;strong&gt;l&lt;/strong&gt; &lt;em&gt;-dot-&lt;/em&gt; &lt;strong&gt;fischer&lt;/strong&gt; &lt;em&gt;-at-&lt;/em&gt; &lt;strong&gt;protonmail&lt;/strong&gt; &lt;em&gt;-dot-&lt;/em&gt; &lt;strong&gt;com&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/lukasffischer&#34;&gt;Twitter&lt;/a&gt;&lt;/p&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/CornuA1&#34;&gt;GitHub&lt;/a&gt;&lt;/p&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/lukas-fischer-106b078b/&#34;&gt;LinkedIn&lt;/a&gt;&lt;/p&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=9xouwcQAAAAJ&amp;amp;hl=en&#34;&gt;Google Scholar&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>init()</title>
      <link>https://cornua1.github.io/posts/initpost/</link>
      <pubDate>Mon, 30 Mar 2020 16:54:08 -0400</pubDate>
      <guid>https://cornua1.github.io/posts/initpost/</guid>
      <description>&lt;p&gt;Welcome to my new website. After a rather extensive hiatus from posting about my PhD work (&lt;a href=&#34;http://mousevr.blogspot.com&#34;&gt;Virtual Reality for Mice&lt;/a&gt;), I&amp;rsquo;ve decided to create a personal website to write the occasional piece on whatever I think might be interesting to others. Chances are, the topics will mostly be at least tangential to the work I do.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>https://cornua1.github.io/about/</link>
      <pubDate>Sun, 29 Mar 2020 18:02:59 -0400</pubDate>
      <guid>https://cornua1.github.io/about/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;https://cornua1.github.io/lukas.jpg&#34; height=&#34;200&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;I am a senior scientist at Merck Research Laboratories where I develop self-supervised computer vision methods for high-throughput imaging analysis. Before joining Merck, I was a research scientist and postdoc in the ([Harnett lab][http://www.markharnett.org/]) at the MIT McGovern Institute for Brain Research. There, I investigated the mechanisms underlying how individual neurons and neural networks create meaningful representations from the multitude of sensory inputs we are bombarded with at any given point int time.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
